# AI Music Synesthesia: Image-to-Music Generator

### An AI-powered application that generates original music from images. It uses Google's Gemini 2.5 Pro to analyze visual features and create descriptive prompts for a music generation model.

![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python) ![Streamlit](https://img.shields.io/badge/Streamlit-1.50.0-orange?logo=streamlit) ![Google Gemini](https://img.shields.io/badge/Google_Gemini-2.5_Pro-blue?logo=google-gemini) ![Stability AI](https://img.shields.io/badge/Stability_AI-API-black?logo=stabilityai)
## üöÄ Overview

This project is a creative, senior-level exploration of **multi-modal AI**. The application, dubbed "AI Music Synesthesia," translates visual information into auditory experiences. Users can upload any image, and the system orchestrates a series of AI models to compose and generate a unique piece of music that reflects the image's mood, colors, and content.

The core of this project lies in its sophisticated **cross-modal prompt engineering pipeline**: it uses a powerful vision-language model (Gemini 2.5 Pro) to "see" and interpret an image, translating visual aesthetics into a rich, descriptive prompt tailored for a state-of-the-art music generation model (Stable Audio 2.0).

## ‚ú® Key Features & Techniques

*   **Multi-Modal AI Pipeline (Image -> Text -> Audio):** Demonstrates the ability to build a complex workflow that bridges three different data modalities, a hallmark of advanced AI engineering.
*   **Vision-Language Model Integration:** Utilizes the powerful multi-modal capabilities of **Google Gemini 2.5 Pro** to perform detailed image analysis and interpretation.
*   **Advanced Prompt Engineering:** The system's intelligence lies in its ability to translate abstract visual concepts (like mood, color theory, and complexity) into concrete musical terms (like tempo, genre, and instrumentation) for the text-to-music model.
*   **State-of-the-Art Music Generation:** Integrates with the **Stability AI API for Stable Audio 2.0**, showcasing experience with cutting-edge, commercially relevant text-to-audio models.
*   **End-to-End System Design:** Builds a complete, user-facing product from the ground up, combining a **Streamlit** front-end with a complex, multi-API backend.

## üõ†Ô∏è How to Run

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/takzen/ai-music-synesthesia.git
    cd ai-music-synesthesia
    ```

2.  **Set up API Keys:**
    *   Create a file named `.env` in the root of the project.
    *   Add your API keys to this file:
        ```
        GOOGLE_API_KEY="YOUR_GOOGLE_AI_KEY"
        STABILITY_API_KEY="YOUR_STABILITY_AI_KEY"
        ```

3.  **Create a virtual environment and install dependencies:**
    *   This project requires Python 3.9+. Create a virtual environment (`uv venv`).
    *   Install the required packages using this command:
        ```bash
        uv pip install streamlit python-dotenv google-generativeai requests Pillow
        ```

4.  **Run the Streamlit application:**
    ```bash
    streamlit run app.py
    ```

## üñºÔ∏è Showcase

| 1. User Uploads an Image                                 | 2. AI Generates a Prompt and Music                        |
| :------------------------------------------------------- | :-------------------------------------------------------- |
| ![User Input](images/01_image_upload.png)                | ![Generated Music](images/02_music_output.png)            |
| *The user uploads any image to serve as the creative seed.* | *The app shows the descriptive prompt created by Gemini and provides a player for the final audio track generated by Stable Audio.* |